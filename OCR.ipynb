{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b0236a",
   "metadata": {},
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ffed2d3-6431-471e-8c21-5938834c0c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92af2bc8",
   "metadata": {},
   "source": [
    "**SIMPLE GREYSCALE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "692dda1d-9dfc-4976-981d-bf9241821145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_resized_grayscale_image(image_path, width=None, height=None):\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(image_path):\n",
    "        print(\"Error: File does not exist at\", image_path)\n",
    "        return\n",
    "\n",
    "    # Check if the file is readable\n",
    "    if not os.access(image_path, os.R_OK):\n",
    "        print(\"Error: Cannot read file at\", image_path)\n",
    "        return\n",
    "\n",
    "    # Read the image from the file path\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    if image is None:\n",
    "        print(\"Error: Unable to load image from\", image_path)\n",
    "        return\n",
    "\n",
    "    # Resize the image if width or height is provided\n",
    "    if width is not None and height is not None:\n",
    "        image = cv2.resize(image, (width, height))\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Display the grayscale image\n",
    "    cv2.imshow(\"Grayscale Image\", gray_image)\n",
    "    cv2.waitKey(0)  # Wait indefinitely until a key is pressed\n",
    "    cv2.destroyAllWindows()  # Close all OpenCV windows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "0a93453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"Desktop/Train_Samples_V0/Train_Samples_V0/20240328_145148.jpg\"\n",
    "display_resized_grayscale_image(image_path, width=600, height=900)  # Specify width and height for resizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ffb98b",
   "metadata": {},
   "source": [
    "**BETTER READABLE PLAIN CONTOUR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "b7007ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_resized_grayscale_image_with_contours(image_path, width=None, height=None):\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(image_path):\n",
    "        print(\"Error: File does not exist at\", image_path)\n",
    "        return\n",
    "\n",
    "    # Check if the file is readable\n",
    "    if not os.access(image_path, os.R_OK):\n",
    "        print(\"Error: Cannot read file at\", image_path)\n",
    "        return\n",
    "\n",
    "    # Read the image from the file path\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    if image is None:\n",
    "        print(\"Error: Unable to load image from\", image_path)\n",
    "        return\n",
    "\n",
    "    # Resize the image if width or height is provided\n",
    "    if width is not None and height is not None:\n",
    "        image = cv2.resize(image, (width, height))\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply convolution for edge detection (you can use other methods too)\n",
    "    edges = cv2.Canny(gray_image, 100, 200)\n",
    "\n",
    "    # Find contours in the edge-detected image\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Draw contours on the original image\n",
    "    image_with_contours = image.copy()\n",
    "    cv2.drawContours(image_with_contours, contours, -1, (0, 255, 0), 2)  # Green color for contours\n",
    "\n",
    "    # Display the image with contours\n",
    "    cv2.imshow(\"Image with Contours\", image_with_contours)\n",
    "    cv2.waitKey(0)  # Wait indefinitely until a key is pressed\n",
    "    cv2.destroyAllWindows()  # Close all OpenCV windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "a9222752",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"Desktop/Train_Samples_V0/Train_Samples_V0/20240328_153456.jpg\"\n",
    "display_resized_grayscale_image_with_contours(image_path, width=600, height=900)  # Specify width and height for resizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280a39d6",
   "metadata": {},
   "source": [
    "**PLAIN CONTOUR MISSES THIN LINES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c682a620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "d38c89f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_threshold(image):\n",
    "    # Compute MWR and AWR for each line\n",
    "    mwr_values = []\n",
    "    awr_values = []\n",
    "    for row in image:\n",
    "        # Count white run-lengths\n",
    "        white_runs = [len(run) for run in np.split(row, np.where(np.diff(row) != 0)[0] + 1) if run.size > 0 and run[0] == 255]\n",
    "        if white_runs:\n",
    "            mwr_values.append(np.median(white_runs))\n",
    "            awr_values.append(len(row) / (len(white_runs) + 1))  # +1 to avoid division by zero\n",
    "    # Check if there are values in mwr_values and awr_values\n",
    "    if mwr_values and awr_values:\n",
    "        # Compute threshold using MWR and AWR\n",
    "        threshold = np.median(mwr_values) * np.median(awr_values)\n",
    "        return threshold\n",
    "    else:\n",
    "        print(\"Error: Unable to compute threshold. Image may not contain any white pixels.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "02694448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bounding_blocks(image, contours, threshold, padding=20):\n",
    "    if threshold is None:\n",
    "        print(\"Error: Threshold value is None. Cannot extract bounding blocks.\")\n",
    "        return []\n",
    "\n",
    "    bounding_blocks = []\n",
    "    for contour in contours:\n",
    "        # Get bounding box of contour\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        # Apply padding\n",
    "        x -= padding\n",
    "        y -= padding\n",
    "        w += 2 * padding\n",
    "        h += 2 * padding\n",
    "        # Check if width is greater than threshold\n",
    "        if w > threshold:\n",
    "            # Merge with existing bounding boxes if overlapping\n",
    "            merged = False\n",
    "            for i, (bx, by, bw, bh) in enumerate(bounding_blocks):\n",
    "                if (x >= bx and x <= bx + bw) or (x + w >= bx and x + w <= bx + bw) or \\\n",
    "                   (bx >= x and bx <= x + w) or (bx + bw >= x and bx + bw <= x + w):\n",
    "                    # Overlapping, merge boxes\n",
    "                    x = min(x, bx)\n",
    "                    y = min(y, by)\n",
    "                    w = max(x + w, bx + bw) - x\n",
    "                    h = max(y + h, by + bh) - y\n",
    "                    bounding_blocks[i] = (x, y, w, h)\n",
    "                    merged = True\n",
    "                    break\n",
    "            if not merged:\n",
    "                bounding_blocks.append((x, y, w, h))\n",
    "    return bounding_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "5ac24805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_resized_grayscale_image_with_contours_and_bounding_blocks(image_path, width=None, height=None):\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(image_path):\n",
    "        print(\"Error: File does not exist at\", image_path)\n",
    "        return\n",
    "\n",
    "    # Check if the file is readable\n",
    "    if not os.access(image_path, os.R_OK):\n",
    "        print(\"Error: Cannot read file at\", image_path)\n",
    "        return\n",
    "\n",
    "    # Read the image from the file path\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    if image is None:\n",
    "        print(\"Error: Unable to load image from\", image_path)\n",
    "        return\n",
    "\n",
    "    # Resize the image if width or height is provided\n",
    "    if width is not None and height is not None:\n",
    "        image = cv2.resize(image, (width, height))\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply convolution for edge detection (you can use other methods too)\n",
    "    edges = cv2.Canny(gray_image, 100, 200)\n",
    "\n",
    "    # Find contours in the edge-detected image\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Compute threshold\n",
    "    threshold = compute_threshold(gray_image)\n",
    "\n",
    "    # Extract bounding blocks based on contours and threshold\n",
    "    bounding_blocks = extract_bounding_blocks(gray_image, contours, threshold)\n",
    "\n",
    "    # Draw contours on the original image\n",
    "    image_with_contours = image.copy()\n",
    "    cv2.drawContours(image_with_contours, contours, -1, (0, 255, 0), 2)  # Green color for contours\n",
    "\n",
    "    # Draw bounding blocks\n",
    "    for x, y, w, h in bounding_blocks:\n",
    "        cv2.rectangle(image_with_contours, (x, y), (x + w, y + h), (0, 0, 255), 2)  # Red color for bounding blocks\n",
    "\n",
    "    # Display the image with contours and bounding blocks\n",
    "    cv2.imshow(\"Image with Contours and Bounding Blocks\", image_with_contours)\n",
    "    cv2.waitKey(0)  # Wait indefinitely until a key is pressed\n",
    "    cv2.destroyAllWindows()  # Close all OpenCV windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "464f89ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unable to compute threshold. Image may not contain any white pixels.\n",
      "Error: Threshold value is None. Cannot extract bounding blocks.\n"
     ]
    }
   ],
   "source": [
    "image_path = \"Desktop/Train_Samples_V0/Train_Samples_V0/20240328_153456.jpg\"\n",
    "display_resized_grayscale_image_with_contours_and_bounding_blocks(image_path, width=600, height=900)  # Specify width and height for resizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618ce9ab",
   "metadata": {},
   "source": [
    "**THINNER AND GREEN CONTOUR RED BOX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7b9d318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_resized_grayscale_image_with_contours_and_bounding_blocks(image_path, width=None, height=None):\n",
    "    import os\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(image_path):\n",
    "        print(\"Error: File does not exist at\", image_path)\n",
    "        return\n",
    "\n",
    "    # Check if the file is readable\n",
    "    if not os.access(image_path, os.R_OK):\n",
    "        print(\"Error: Cannot read file at\", image_path)\n",
    "        return\n",
    "\n",
    "    # Read the image from the file path\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    if image is None:\n",
    "        print(\"Error: Unable to load image from\", image_path)\n",
    "        return\n",
    "\n",
    "    # Resize the image if width or height is provided\n",
    "    if width is not None and height is not None:\n",
    "        image = cv2.resize(image, (width, height))\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply smaller convolution to preserve finer details\n",
    "    kernel = np.ones((3, 3), np.float32) / 50\n",
    "    smoothed_image = cv2.filter2D(gray_image, -1, kernel)\n",
    "\n",
    "    # Apply adaptive thresholding\n",
    "    binary_image = cv2.adaptiveThreshold(smoothed_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "    # Find contours in the binary image\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Create a blank canvas for drawing the polygon boundaries and bounding boxes\n",
    "    canvas = np.zeros_like(image)\n",
    "\n",
    "    # Draw contours and bounding boxes on the canvas\n",
    "    for contour in contours:\n",
    "        # Draw contours with reduced thickness\n",
    "        cv2.drawContours(canvas, [contour], -1, (0, 255, 0), 1)  # Thickness set to 1\n",
    "        # Get bounding box coordinates\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        # Draw bounding boxes\n",
    "        cv2.rectangle(canvas, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "    # Display the canvas with polygon boundaries and bounding boxes\n",
    "    cv2.imshow(\"Contours and Bounding Boxes\", canvas)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "101e134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"Desktop/Train_Samples_V0/Train_Samples_V0/20240328_153456.jpg\"\n",
    "display_resized_grayscale_image_with_contours_and_bounding_blocks(image_path, width=600, height=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43ca64e",
   "metadata": {},
   "source": [
    "**THINNER AND GREEN CONTOUR NO BOX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7d5620c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_resized_grayscale_image_with_contours_and_bounding_blocks(image_path, width=None, height=None):\n",
    "    \n",
    "    \n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(image_path):\n",
    "        print(\"Error: File does not exist at\", image_path)\n",
    "        return\n",
    "\n",
    "    # Check if the file is readable\n",
    "    if not os.access(image_path, os.R_OK):\n",
    "        print(\"Error: Cannot read file at\", image_path)\n",
    "        return\n",
    "\n",
    "    # Read the image from the file path\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    if image is None:\n",
    "        print(\"Error: Unable to load image from\", image_path)\n",
    "        return\n",
    "\n",
    "    # Resize the image if width or height is provided\n",
    "    if width is not None and height is not None:\n",
    "        image = cv2.resize(image, (width, height))\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply smaller convolution to preserve finer details\n",
    "    kernel = np.ones((3, 3), np.float32) / 50\n",
    "    smoothed_image = cv2.filter2D(gray_image, -1, kernel)\n",
    "\n",
    "    # Apply adaptive thresholding\n",
    "    binary_image = cv2.adaptiveThreshold(smoothed_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "    # Find contours in the binary image\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Create a blank canvas for drawing the polygon boundaries\n",
    "    canvas = np.zeros_like(image)\n",
    "\n",
    "    # Draw contours on the canvas\n",
    "    for contour in contours:\n",
    "        # Draw contours with reduced thickness\n",
    "        cv2.drawContours(canvas, [contour], -1, (0, 255, 0), 1)  # Thickness set to 1\n",
    "\n",
    "    # Display the canvas with polygon boundaries\n",
    "    cv2.imshow(\"Contours\", canvas)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6d2e1a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"Desktop/Train_Samples_V0/Train_Samples_V0/20240328_153456.jpg\"\n",
    "display_resized_grayscale_image_with_contours_and_bounding_blocks(image_path, width=600, height=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dbd2fe",
   "metadata": {},
   "source": [
    "**NOT A GOOD APPROACH COMPUTATIONALLY COSTLY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "bb80d555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_edges_on_grid(image_path):\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Define the grid parameters\n",
    "    rows = 400\n",
    "    cols = 600\n",
    "    height, width = gray_image.shape\n",
    "\n",
    "    # Calculate grid spacing\n",
    "    grid_spacing_x = width // (cols + 1)\n",
    "    grid_spacing_y = height // (rows + 1)\n",
    "\n",
    "    # Define the Sobel kernel for edge detection\n",
    "    sobel_kernel_x = np.array([[-1, 0, 1],\n",
    "                               [-2, 0, 2],\n",
    "                               [-1, 0, 1]])\n",
    "\n",
    "    # Iterate over each grid cell\n",
    "    for y in range(grid_spacing_y, height, grid_spacing_y):\n",
    "        for x in range(grid_spacing_x, width, grid_spacing_x):\n",
    "            # Extract the current grid cell\n",
    "            cell_image = gray_image[y-grid_spacing_y:y, x-grid_spacing_x:x]\n",
    "\n",
    "            # Apply Sobel operator for edge detection\n",
    "            edges_x = cv2.filter2D(cell_image, -1, sobel_kernel_x)\n",
    "\n",
    "            # Find the position of leftmost and rightmost edges\n",
    "            left_edge_x = np.argmax(edges_x, axis=1).min()\n",
    "            right_edge_x = np.argmax(edges_x, axis=1).max()\n",
    "\n",
    "            # Draw red lines indicating leftmost and rightmost edges\n",
    "            left_edge_start = (x-grid_spacing_x+left_edge_x, y)\n",
    "            left_edge_end = (x-grid_spacing_x+left_edge_x, y-grid_spacing_y)\n",
    "            right_edge_start = (x-grid_spacing_x+right_edge_x, y)\n",
    "            right_edge_end = (x-grid_spacing_x+right_edge_x, y-grid_spacing_y)\n",
    "\n",
    "            # Check the shades of pixels on both sides of the red lines\n",
    "            left_shade = gray_image[left_edge_end[1], left_edge_end[0]]\n",
    "            right_shade = gray_image[right_edge_end[1], right_edge_end[0]]\n",
    "\n",
    "            # Check conditions to remove or keep the red lines\n",
    "            if left_shade > 150 and right_shade > 150:\n",
    "                # Both sides are light, remove the red line\n",
    "                continue\n",
    "            elif left_shade < 100 and right_shade < 100:\n",
    "                # Both sides are dark, remove the red line\n",
    "                continue\n",
    "            else:\n",
    "                # At least one side is dark and the other side is light, keep the red line\n",
    "                cv2.line(image, left_edge_start, left_edge_end, (0, 0, 255), 1)  # Red color\n",
    "                cv2.line(image, right_edge_start, right_edge_end, (0, 0, 255), 1)  # Red color\n",
    "\n",
    "    # Draw blue grids\n",
    "    for y in range(grid_spacing_y, height, grid_spacing_y):\n",
    "        cv2.line(image, (0, y), (width, y), (255, 0, 0), 1)\n",
    "    for x in range(grid_spacing_x, width, grid_spacing_x):\n",
    "        cv2.line(image, (x, 0), (x, height), (255, 0, 0), 1)\n",
    "\n",
    "    # Display the image with red edges on blue grids\n",
    "    resized_image = cv2.resize(image, (600, 900))\n",
    "    cv2.imshow(\"Image with Red Edges on Blue Grids\", resized_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b8581f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"Desktop/Train_Samples_V0/Train_Samples_V0/20240328_153456.jpg\"\n",
    "draw_edges_on_grid(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f58b6c2",
   "metadata": {},
   "source": [
    "**IMPROVING THE BEST ONE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "b05710ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_ocr_with_edge_detection(image_path, merge_threshold=50):\n",
    "    # Read the input image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Resize the image to 600x900 pixels\n",
    "    image = cv2.resize(image, (600, 900))\n",
    "\n",
    "    # Step 1: Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Step 2: Define the Sobel kernel for edge detection\n",
    "    sobel_kernel_x = np.array([[-1, 0, 1],\n",
    "                               [-2, 0, 2],\n",
    "                               [-1, 0, 1]])\n",
    "\n",
    "    sobel_kernel_y = np.array([[-1, -2, -1],\n",
    "                               [0, 0, 0],\n",
    "                               [1, 2, 1]])\n",
    "\n",
    "    # Step 3: Perform convolution for horizontal and vertical edges\n",
    "    edges_x = cv2.filter2D(gray, -1, sobel_kernel_x)\n",
    "    edges_y = cv2.filter2D(gray, -1, sobel_kernel_y)\n",
    "\n",
    "    # Step 4: Combine horizontal and vertical edges\n",
    "    edges = cv2.addWeighted(edges_x, 0.5, edges_y, 0.5, 0)\n",
    "\n",
    "    # Step 5: Threshold the edge detection result\n",
    "    _, thresholded = cv2.threshold(edges, 100, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Step 6: Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Merge nearby bounding boxes\n",
    "    merged_contours = merge_contours(contours, merge_threshold)\n",
    "\n",
    "    # Step 7: Draw bounding boxes around detected contours\n",
    "    for contour in merged_contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow('OCR Result', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def merge_contours(contours, merge_threshold):\n",
    "    merged_contours = []\n",
    "    for contour in contours:\n",
    "        if merged_contours:\n",
    "            merged = False\n",
    "            for i, merged_contour in enumerate(merged_contours):\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                x_merged, y_merged, w_merged, h_merged = cv2.boundingRect(merged_contour)\n",
    "                distance = np.sqrt((x - x_merged)**2 + (y - y_merged)**2)\n",
    "                if distance < merge_threshold:\n",
    "                    # Merge the contours\n",
    "                    merged_contours[i] = np.vstack((merged_contour, contour))\n",
    "                    merged = True\n",
    "                    break\n",
    "            if not merged:\n",
    "                merged_contours.append(contour)\n",
    "        else:\n",
    "            merged_contours.append(contour)\n",
    "    return merged_contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "aba4e46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'Desktop/Train_Samples_V0/Train_Samples_V0/20240328_153456.jpg'\n",
    "perform_ocr_with_edge_detection(image_path, merge_threshold=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb690d5",
   "metadata": {},
   "source": [
    "**MERGED+SMOOTHENED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "b21d0ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def improved_perform_ocr_with_edge_detection(image_path, merge_threshold=50, smoothing_radius=10):\n",
    "    # Read the input image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Resize the image to 600x900 pixels\n",
    "    image = cv2.resize(image, (600, 900))\n",
    "\n",
    "    # Step 1: Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Step 2: Define the Sobel kernel for edge detection\n",
    "    sobel_kernel_x = np.array([[-1, 0, 1],\n",
    "                               [-2, 0, 2],\n",
    "                               [-1, 0, 1]])\n",
    "\n",
    "    sobel_kernel_y = np.array([[-1, -2, -1],\n",
    "                               [0, 0, 0],\n",
    "                               [1, 2, 1]])\n",
    "\n",
    "    # Step 3: Perform convolution for horizontal and vertical edges\n",
    "    edges_x = cv2.filter2D(gray, -1, sobel_kernel_x)\n",
    "    edges_y = cv2.filter2D(gray, -1, sobel_kernel_y)\n",
    "\n",
    "    # Step 4: Combine horizontal and vertical edges\n",
    "    edges = cv2.addWeighted(edges_x, 0.5, edges_y, 0.5, 0)\n",
    "\n",
    "    # Step 5: Threshold the edge detection result\n",
    "    _, thresholded = cv2.threshold(edges, 100, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Step 6: Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Merge nearby bounding boxes\n",
    "    merged_contours = merge_contours(contours, merge_threshold)\n",
    "\n",
    "    # Smooth outer boxes\n",
    "    smoothed_boxes = smooth_outer_boxes(merged_contours, smoothing_radius)\n",
    "\n",
    "    # Step 7: Draw bounding boxes around detected contours\n",
    "    for box in smoothed_boxes:\n",
    "        x, y, w, h = cv2.boundingRect(box)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow('OCR Result', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def merge_contours(contours, merge_threshold):\n",
    "    merged_contours = []\n",
    "    for contour in contours:\n",
    "        if merged_contours:\n",
    "            merged = False\n",
    "            for i, merged_contour in enumerate(merged_contours):\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                x_merged, y_merged, w_merged, h_merged = cv2.boundingRect(merged_contour)\n",
    "                distance = np.sqrt((x - x_merged)**2 + (y - y_merged)**2)\n",
    "                if distance < merge_threshold:\n",
    "                    # Merge the contours\n",
    "                    merged_contours[i] = np.vstack((merged_contour, contour))\n",
    "                    merged = True\n",
    "                    break\n",
    "            if not merged:\n",
    "                merged_contours.append(contour)\n",
    "        else:\n",
    "            merged_contours.append(contour)\n",
    "    return merged_contours\n",
    "\n",
    "def smooth_outer_boxes(contours, smoothing_radius):\n",
    "    smoothed_boxes = []\n",
    "    for contour in contours:\n",
    "        epsilon = 0.01 * cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "        smoothed_boxes.append(cv2.convexHull(approx))\n",
    "    return smoothed_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "21221f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'Desktop/Train_Samples_V0/Train_Samples_V0/20240328_153456.jpg'\n",
    "improved_perform_ocr_with_edge_detection(image_path, merge_threshold=15, smoothing_radius=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "eb5a29a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'Desktop/Train_Samples_V0/Train_Samples_V0/20240328_154830.jpg'\n",
    "improved_perform_ocr_with_edge_detection(image_path, merge_threshold=16, smoothing_radius=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bab6a91",
   "metadata": {},
   "source": [
    "**ADDING ROWS SEPERATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "7e46cea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def improved_perform_ocr_with_edge_detection(image_path, merge_threshold=16, smoothing_radius=20):\n",
    "    # Read the input image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Resize the image to 600x900 pixels\n",
    "    image = cv2.resize(image, (600, 900))\n",
    "\n",
    "    # Add uniformly spaced horizontal lines\n",
    "    num_lines = 10\n",
    "    height, width, _ = image.shape\n",
    "    spacing = height // (num_lines + 1)\n",
    "    for i in range(1, num_lines + 1):\n",
    "        y = i * spacing\n",
    "        cv2.line(image, (0, y), (width, y), (0, 0, 255), 1)  # Red lines with thickness 1\n",
    "\n",
    "    # Step 1: Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Step 2: Define the Sobel kernel for edge detection\n",
    "    sobel_kernel_x = np.array([[-1, 0, 1],\n",
    "                               [-2, 0, 2],\n",
    "                               [-1, 0, 1]])\n",
    "\n",
    "    sobel_kernel_y = np.array([[-1, -2, -1],\n",
    "                               [0, 0, 0],\n",
    "                               [1, 2, 1]])\n",
    "\n",
    "    # Step 3: Perform convolution for horizontal and vertical edges\n",
    "    edges_x = cv2.filter2D(gray, -1, sobel_kernel_x)\n",
    "    edges_y = cv2.filter2D(gray, -1, sobel_kernel_y)\n",
    "\n",
    "    # Step 4: Combine horizontal and vertical edges\n",
    "    edges = cv2.addWeighted(edges_x, 0.5, edges_y, 0.5, 0)\n",
    "\n",
    "    # Step 5: Threshold the edge detection result\n",
    "    _, thresholded = cv2.threshold(edges, 100, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Step 6: Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Merge nearby bounding boxes\n",
    "    merged_contours = merge_contours(contours, merge_threshold)\n",
    "\n",
    "    # Smooth outer boxes\n",
    "    smoothed_boxes = smooth_outer_boxes(merged_contours, smoothing_radius)\n",
    "\n",
    "    # Step 7: Draw bounding boxes around detected contours\n",
    "    for box in smoothed_boxes:\n",
    "        x, y, w, h = cv2.boundingRect(box)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow('OCR Result', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def merge_contours(contours, merge_threshold):\n",
    "    merged_contours = []\n",
    "    for contour in contours:\n",
    "        if merged_contours:\n",
    "            merged = False\n",
    "            for i, merged_contour in enumerate(merged_contours):\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                x_merged, y_merged, w_merged, h_merged = cv2.boundingRect(merged_contour)\n",
    "                distance = np.sqrt((x - x_merged)**2 + (y - y_merged)**2)\n",
    "                if distance < merge_threshold:\n",
    "                    # Merge the contours\n",
    "                    merged_contours[i] = np.vstack((merged_contour, contour))\n",
    "                    merged = True\n",
    "                    break\n",
    "            if not merged:\n",
    "                merged_contours.append(contour)\n",
    "        else:\n",
    "            merged_contours.append(contour)\n",
    "    return merged_contours\n",
    "\n",
    "def smooth_outer_boxes(contours, smoothing_radius):\n",
    "    smoothed_boxes = []\n",
    "    for contour in contours:\n",
    "        epsilon = 0.01 * cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "        smoothed_boxes.append(cv2.convexHull(approx))\n",
    "    return smoothed_boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "40aa383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'Desktop/Train_Samples_V0/Train_Samples_V0/20240328_154830.jpg'\n",
    "improved_perform_ocr_with_edge_detection(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fec15ac",
   "metadata": {},
   "source": [
    "**RUNNING ON THE DIR**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60beb8e",
   "metadata": {},
   "source": [
    "**FIRST DIR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "86fd0c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "c4a758b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:53<00:00,  1.92s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def improved_perform_ocr_with_edge_detection(image_path, merge_threshold=16, smoothing_radius=20):\n",
    "    # Read the input image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Resize the image to 600x900 pixels\n",
    "    image = cv2.resize(image, (600, 900))\n",
    "\n",
    "    # Add uniformly spaced horizontal lines\n",
    "    num_lines = 10\n",
    "    height, width, _ = image.shape\n",
    "    spacing = height // (num_lines + 1)\n",
    "    for i in range(1, num_lines + 1):\n",
    "        y = i * spacing\n",
    "        cv2.line(image, (0, y), (width, y), (0, 0, 255), 1)  # Red lines with thickness 1\n",
    "\n",
    "    # Step 1: Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Step 2: Define the Sobel kernel for edge detection\n",
    "    sobel_kernel_x = np.array([[-1, 0, 1],\n",
    "                               [-2, 0, 2],\n",
    "                               [-1, 0, 1]])\n",
    "\n",
    "    sobel_kernel_y = np.array([[-1, -2, -1],\n",
    "                               [0, 0, 0],\n",
    "                               [1, 2, 1]])\n",
    "\n",
    "    # Step 3: Perform convolution for horizontal and vertical edges\n",
    "    edges_x = cv2.filter2D(gray, -1, sobel_kernel_x)\n",
    "    edges_y = cv2.filter2D(gray, -1, sobel_kernel_y)\n",
    "\n",
    "    # Step 4: Combine horizontal and vertical edges\n",
    "    edges = cv2.addWeighted(edges_x, 0.5, edges_y, 0.5, 0)\n",
    "\n",
    "    # Step 5: Threshold the edge detection result\n",
    "    _, thresholded = cv2.threshold(edges, 100, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Step 6: Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Merge nearby bounding boxes\n",
    "    merged_contours = merge_contours(contours, merge_threshold)\n",
    "\n",
    "    # Smooth outer boxes\n",
    "    smoothed_boxes = smooth_outer_boxes(merged_contours, smoothing_radius)\n",
    "\n",
    "    # Step 7: Draw bounding boxes around detected contours\n",
    "    for box in smoothed_boxes:\n",
    "        x, y, w, h = cv2.boundingRect(box)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Save the result image with bounding boxes\n",
    "    result_path = os.path.join(os.path.expanduser(\"~\"), 'Desktop', 'result_images', os.path.basename(image_path))\n",
    "    cv2.imwrite(result_path, image)\n",
    "\n",
    "def merge_contours(contours, merge_threshold):\n",
    "    merged_contours = []\n",
    "    for contour in contours:\n",
    "        if merged_contours:\n",
    "            merged = False\n",
    "            for i, merged_contour in enumerate(merged_contours):\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                x_merged, y_merged, w_merged, h_merged = cv2.boundingRect(merged_contour)\n",
    "                distance = np.sqrt((x - x_merged)**2 + (y - y_merged)**2)\n",
    "                if distance < merge_threshold:\n",
    "                    # Merge the contours\n",
    "                    merged_contours[i] = np.vstack((merged_contour, contour))\n",
    "                    merged = True\n",
    "                    break\n",
    "            if not merged:\n",
    "                merged_contours.append(contour)\n",
    "        else:\n",
    "            merged_contours.append(contour)\n",
    "    return merged_contours\n",
    "\n",
    "def smooth_outer_boxes(contours, smoothing_radius):\n",
    "    smoothed_boxes = []\n",
    "    for contour in contours:\n",
    "        epsilon = 0.01 * cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "        smoothed_boxes.append(cv2.convexHull(approx))\n",
    "    return smoothed_boxes\n",
    "\n",
    "# Create the result_images directory if it doesn't exist on the desktop\n",
    "result_images_dir = os.path.join(os.path.expanduser(\"~\"), 'Desktop', 'result_images')\n",
    "if not os.path.exists(result_images_dir):\n",
    "    os.makedirs(result_images_dir)\n",
    "\n",
    "# Process all images in a folder\n",
    "image_folder = 'Desktop/Train_Samples_V0/Train_Samples_V0/'\n",
    "for filename in tqdm(os.listdir(image_folder)):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        improved_perform_ocr_with_edge_detection(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc46350",
   "metadata": {},
   "source": [
    "**SECOND DIR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "edf7a779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_threshold(image):\n",
    "    # Compute MWR and AWR for each line\n",
    "    mwr_values = []\n",
    "    awr_values = []\n",
    "    for row in image:\n",
    "        # Count white run-lengths\n",
    "        white_runs = [len(run) for run in np.split(row, np.where(np.diff(row) != 0)[0] + 1) if run.size > 0 and run[0] == 255]\n",
    "        if white_runs:\n",
    "            mwr_values.append(np.median(white_runs))\n",
    "            awr_values.append(len(row) / (len(white_runs) + 1))  # +1 to avoid division by zero\n",
    "    # Check if there are values in mwr_values and awr_values\n",
    "    if mwr_values and awr_values:\n",
    "        # Compute threshold using MWR and AWR\n",
    "        threshold = np.median(mwr_values) * np.median(awr_values)\n",
    "        return threshold\n",
    "    else:\n",
    "        print(\"Error: Unable to compute threshold. Image may not contain any white pixels.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "52a66b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bounding_blocks(image, contours, threshold, padding=20):\n",
    "    if threshold is None:\n",
    "        print(\"Error: Threshold value is None. Cannot extract bounding blocks.\")\n",
    "        return []\n",
    "\n",
    "    bounding_blocks = []\n",
    "    for contour in contours:\n",
    "        # Get bounding box of contour\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        # Apply padding\n",
    "        x -= padding\n",
    "        y -= padding\n",
    "        w += 2 * padding\n",
    "        h += 2 * padding\n",
    "        # Check if width is greater than threshold\n",
    "        if w > threshold:\n",
    "            # Merge with existing bounding boxes if overlapping\n",
    "            merged = False\n",
    "            for i, (bx, by, bw, bh) in enumerate(bounding_blocks):\n",
    "                if (x >= bx and x <= bx + bw) or (x + w >= bx and x + w <= bx + bw) or \\\n",
    "                   (bx >= x and bx <= x + w) or (bx + bw >= x and bx + bw <= x + w):\n",
    "                    # Overlapping, merge boxes\n",
    "                    x = min(x, bx)\n",
    "                    y = min(y, by)\n",
    "                    w = max(x + w, bx + bw) - x\n",
    "                    h = max(y + h, by + bh) - y\n",
    "                    bounding_blocks[i] = (x, y, w, h)\n",
    "                    merged = True\n",
    "                    break\n",
    "            if not merged:\n",
    "                bounding_blocks.append((x, y, w, h))\n",
    "    return bounding_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83bdf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_resized_grayscale_image_with_contours_and_bounding_blocks(image_path, output_dir, width=None, height=None):\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(image_path):\n",
    "        print(\"Error: File does not exist at\", image_path)\n",
    "        return\n",
    "\n",
    "    # Check if the file is readable\n",
    "    if not os.access(image_path, os.R_OK):\n",
    "        print(\"Error: Cannot read file at\", image_path)\n",
    "        return\n",
    "\n",
    "    # Read the image from the file path\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    if image is None:\n",
    "        print(\"Error: Unable to load image from\", image_path)\n",
    "        return\n",
    "\n",
    "    # Resize the image if width or height is provided\n",
    "    if width is not None and height is not None:\n",
    "        image = cv2.resize(image, (width, height))\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply convolution for edge detection (you can use other methods too)\n",
    "    edges = cv2.Canny(gray_image, 100, 200)\n",
    "\n",
    "    # Find contours in the edge-detected image\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Compute threshold\n",
    "    threshold = compute_threshold(gray_image)\n",
    "\n",
    "    # Extract bounding blocks based on contours and threshold\n",
    "    bounding_blocks = extract_bounding_blocks(gray_image, contours, threshold)\n",
    "\n",
    "    # Draw contours on the original image\n",
    "    image_with_contours = image.copy()\n",
    "    cv2.drawContours(image_with_contours, contours, -1, (0, 255, 0), 2)  # Green color for contours\n",
    "\n",
    "    # Draw bounding blocks\n",
    "    for x, y, w, h in bounding_blocks:\n",
    "        cv2.rectangle(image_with_contours, (x, y), (x + w, y + h), (0, 0, 255), 2)  # Red color for bounding blocks\n",
    "\n",
    "    # Save the output image\n",
    "    filename = os.path.basename(image_path)\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    cv2.imwrite(output_path, image_with_contours)\n",
    "\n",
    "# Directory containing input images\n",
    "input_dir = r\"Desktop\\Train_Samples_V0\\Train_Samples_V0\"\n",
    "\n",
    "# Directory to save output images\n",
    "output_dir = r\"Desktop\\result_image_2\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop through input images with tqdm progress bar\n",
    "for filename in tqdm(os.listdir(input_dir)):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        input_image_path = os.path.join(input_dir, filename)\n",
    "        display_resized_grayscale_image_with_contours_and_bounding_blocks(input_image_path, output_dir, width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bd97f6",
   "metadata": {},
   "source": [
    "**DIR 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad88804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_final_resized_grayscale_image_with_contours_and_bounding_blocks(image_path, output_dir, width=None, height=None):\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(image_path):\n",
    "        print(\"Error: File does not exist at\", image_path)\n",
    "        return\n",
    "\n",
    "    # Check if the file is readable\n",
    "    if not os.access(image_path, os.R_OK):\n",
    "        print(\"Error: Cannot read file at\", image_path)\n",
    "        return\n",
    "\n",
    "    # Read the image from the file path\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    if image is None:\n",
    "        print(\"Error: Unable to load image from\", image_path)\n",
    "        return\n",
    "\n",
    "    # Resize the image if width or height is provided\n",
    "    if width is not None and height is not None:\n",
    "        image = cv2.resize(image, (width, height))\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply convolution for edge detection (you can use other methods too)\n",
    "    edges = cv2.Canny(gray_image, 100, 200)\n",
    "\n",
    "    # Find contours in the edge-detected image\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Compute threshold\n",
    "    threshold = compute_threshold(gray_image)\n",
    "\n",
    "    # Extract bounding blocks based on contours and threshold\n",
    "    bounding_blocks = extract_bounding_blocks(gray_image, contours, threshold)\n",
    "\n",
    "    # Draw contours on the original image\n",
    "    image_with_contours = image.copy()\n",
    "    cv2.drawContours(image_with_contours, contours, -1, (0, 255, 0), 1)  # Green color for contours\n",
    "\n",
    "    # Draw bounding blocks\n",
    "    for x, y, w, h in bounding_blocks:\n",
    "        cv2.rectangle(image_with_contours, (x, y), (x + w, y + h), (0, 0, 255), 1)  # Red color for bounding blocks\n",
    "\n",
    "    # Save the output image\n",
    "    filename = os.path.basename(image_path)\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    cv2.imwrite(output_path, image_with_contours)\n",
    "\n",
    "# Directory containing input images\n",
    "input_dir = r\"Desktop\\Train_Samples_V0\\Train_Samples_V0\"\n",
    "\n",
    "# Directory to save output images\n",
    "output_dir = r\"Desktop\\result_image_3\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop through input images with tqdm progress bar\n",
    "for filename in tqdm(os.listdir(input_dir)):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        input_image_path = os.path.join(input_dir, filename)\n",
    "        display_resized_grayscale_image_with_contours_and_bounding_blocks(input_image_path, output_dir, width=800, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba91573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_resized_grayscale_image_with_contours_and_bounding_blocks(image_path, output_dir, width=None, height=None):\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(image_path):\n",
    "        print(\"Error: File does not exist at\", image_path)\n",
    "        return\n",
    "\n",
    "    # Check if the file is readable\n",
    "    if not os.access(image_path, os.R_OK):\n",
    "        print(\"Error: Cannot read file at\", image_path)\n",
    "        return\n",
    "\n",
    "    # Read the image from the file path\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    if image is None:\n",
    "        print(\"Error: Unable to load image from\", image_path)\n",
    "        return\n",
    "\n",
    "    # Resize the image if width or height is provided\n",
    "    if width is not None and height is not None:\n",
    "        image = cv2.resize(image, (width, height))\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply convolution for edge detection (you can use other methods too)\n",
    "    edges = cv2.Canny(gray_image, 100, 200)\n",
    "\n",
    "    # Find contours in the edge-detected image\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Compute threshold\n",
    "    threshold = compute_threshold(gray_image)\n",
    "\n",
    "    # Extract bounding blocks based on contours and threshold\n",
    "    bounding_blocks = extract_bounding_blocks(gray_image, contours, threshold)\n",
    "\n",
    "    # Draw contours on the original image\n",
    "    image_with_contours = image.copy()\n",
    "    cv2.drawContours(image_with_contours, contours, -1, (0, 255, 0), 2)  # Green color for contours\n",
    "\n",
    "    # Draw bounding blocks\n",
    "    for x, y, w, h in bounding_blocks:\n",
    "        cv2.rectangle(image_with_contours, (x, y), (x + w, y + h), (0, 0, 255), 2)  # Red color for bounding blocks\n",
    "\n",
    "    # Save the output image\n",
    "    filename = os.path.basename(image_path)\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    cv2.imwrite(output_path, image_with_contours)\n",
    "\n",
    "# Directory containing input images\n",
    "input_dir = r\"Desktop\\Train_Samples_V0\\Train_Samples_V0\"\n",
    "\n",
    "# Directory to save output images\n",
    "output_dir = r\"Desktop\\result_image_2\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop through input images with tqdm progress bar\n",
    "for filename in tqdm(os.listdir(input_dir)):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        input_image_path = os.path.join(input_dir, filename)\n",
    "        display_resized_grayscale_image_with_contours_and_bounding_blocks(input_image_path, output_dir, width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c59a41",
   "metadata": {},
   "source": [
    "**APPLYING BOTH THE BEST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5573a3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_threshold(image):\n",
    "    # Compute MWR and AWR for each line\n",
    "    mwr_values = []\n",
    "    awr_values = []\n",
    "    for row in image:\n",
    "        # Count white run-lengths\n",
    "        white_runs = [len(run) for run in np.split(row, np.where(np.diff(row) != 0)[0] + 1) if run.size > 0 and run[0] == 255]\n",
    "        if white_runs:\n",
    "            mwr_values.append(np.median(white_runs))\n",
    "            awr_values.append(len(row) / (len(white_runs) + 1))  # +1 to avoid division by zero\n",
    "    # Check if there are values in mwr_values and awr_values\n",
    "    if mwr_values and awr_values:\n",
    "        # Compute threshold using MWR and AWR\n",
    "        threshold = np.median(mwr_values) * np.median(awr_values)\n",
    "        return threshold\n",
    "    else:\n",
    "        print(\"Error: Unable to compute threshold. Image may not contain any white pixels.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a39c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432094c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bounding_blocks(image, contours, threshold, padding=20):\n",
    "    if threshold is None:\n",
    "        print(\"Error: Threshold value is None. Cannot extract bounding blocks.\")\n",
    "        return []\n",
    "\n",
    "    bounding_blocks = []\n",
    "    for contour in contours:\n",
    "        # Get bounding box of contour\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        # Apply padding\n",
    "        x -= padding\n",
    "        y -= padding\n",
    "        w += 2 * padding\n",
    "        h += 2 * padding\n",
    "        # Check if width is greater than threshold\n",
    "        if w > threshold:\n",
    "            # Merge with existing bounding boxes if overlapping\n",
    "            merged = False\n",
    "            for i, (bx, by, bw, bh) in enumerate(bounding_blocks):\n",
    "                if (x >= bx and x <= bx + bw) or (x + w >= bx and x + w <= bx + bw) or \\\n",
    "                   (bx >= x and bx <= x + w) or (bx + bw >= x and bx + bw <= x + w):\n",
    "                    # Overlapping, merge boxes\n",
    "                    x = min(x, bx)\n",
    "                    y = min(y, by)\n",
    "                    w = max(x + w, bx + bw) - x\n",
    "                    h = max(y + h, by + bh) - y\n",
    "                    bounding_blocks[i] = (x, y, w, h)\n",
    "                    merged = True\n",
    "                    break\n",
    "            if not merged:\n",
    "                bounding_blocks.append((x, y, w, h))\n",
    "    return bounding_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "13ea3123",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'Desktop/Train_Samples_V0/Train_Samples_V0/20240328_154830.jpg'\n",
    "display_final_image(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526e06e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
